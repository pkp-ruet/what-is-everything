const fs = require("fs").promises;
const path = require("path");
const { MongoClient } = require("mongodb");
require("dotenv").config();

// MongoDB configuration
const MONGODB_URI = process.env.MONGODB_URI;
const DATABASE_NAME = process.env.DATABASE_NAME;
const COLLECTION_NAME = "blogs";

// Folder containing text files
const TEXT_FILES_FOLDER = process.env.TEXT_FILES_FOLDER || "./text-files";

// Blog model schema (for reference)
const blogSchema = {
  // id: ObjectId (automatically generated by MongoDB)
  title: String,
  content: String,
  createdAt: Date,
};

/**
 * Connects to the MongoDB database.
 * @returns {Promise<MongoClient>} The connected MongoClient instance.
 */
async function connectToMongoDB() {
  const client = new MongoClient(MONGODB_URI);
  await client.connect();
  console.log("Connected to MongoDB");
  return client;
}

/**
 * Reads text files from a specified folder and parses them into blog objects.
 * The filename (without extension) is used as the blog title.
 * @param {string} folderPath - The path to the folder containing text files.
 * @returns {Promise<Array<Object>>} An array of blog objects.
 */
async function readTextFiles(folderPath) {
  try {
    // Check if folder exists
    await fs.access(folderPath);

    const files = await fs.readdir(folderPath);
    const textFiles = files.filter((file) => file.endsWith(".txt"));

    if (textFiles.length === 0) {
      console.log("No .txt files found in the specified folder");
      return [];
    }

    const blogs = [];

    for (const file of textFiles) {
      const filePath = path.join(folderPath, file);
      const content = await fs.readFile(filePath, "utf8");

      // Extract title from filename (removing extension)
      const title = path.parse(file).name.trim();

      blogs.push({
        title,
        content: content.trim(),
        createdAt: new Date(),
      });

      console.log(`‚úì Read file: ${file} (${content.length} characters)`);
    }

    return blogs;
  } catch (error) {
    if (error.code === "ENOENT") {
      console.error(`Error: Folder '${folderPath}' does not exist`);
      console.log("Please create the folder and add some .txt files");
    } else {
      console.error("Error reading files:", error.message);
    }
    throw error;
  }
}

/**
 * Checks for existing blogs with the same titles in the database
 * and filters out duplicates from the provided list.
 * @param {Array<Object>} blogs - An array of blog objects to check.
 * @param {import('mongodb').Collection} collection - The MongoDB collection to query.
 * @returns {Promise<Array<Object>>} A new array containing only non-duplicate blogs.
 */
async function checkForDuplicates(blogs, collection) {
  const titles = blogs.map((blog) => blog.title);
  const existingBlogs = await collection
    .find({ title: { $in: titles } })
    .toArray();

  if (existingBlogs.length > 0) {
    console.log("\nWarning: Found existing blogs with the same titles:");
    existingBlogs.forEach((blog) => {
      console.log(`  - "${blog.title}" (ID: ${blog._id})`);
    });

    // Filter out duplicates
    const existingTitles = existingBlogs.map((blog) => blog.title);
    const newBlogs = blogs.filter(
      (blog) => !existingTitles.includes(blog.title)
    );

    console.log(
      `Skipping ${existingBlogs.length} duplicate(s), will save ${newBlogs.length} new blog(s)`
    );
    return newBlogs;
  }

  return blogs;
}

/**
 * Saves a list of blog objects to MongoDB, handling duplicates.
 * @param {Array<Object>} blogs - An array of blog objects to save.
 * @param {MongoClient} client - The MongoDB client instance.
 * @returns {Promise<Object>} An object containing the inserted count and the new blogs.
 */
async function saveBlogsToMongoDB(blogs, client) {
  try {
    const db = client.db(DATABASE_NAME);
    const collection = db.collection(COLLECTION_NAME);

    if (blogs.length === 0) {
      console.log("No new blogs to save");
      return { insertedCount: 0, blogs: [] };
    }

    // Check for duplicates
    const newBlogs = await checkForDuplicates(blogs, collection);

    if (newBlogs.length === 0) {
      console.log("All blogs already exist in the database");
      return { insertedCount: 0, blogs: [] };
    }

    const result = await collection.insertMany(newBlogs);
    console.log(
      `\n‚úÖ Successfully saved ${result.insertedCount} blog(s) to MongoDB`
    );

    // Display the inserted documents
    console.log("\nInserted blogs:");
    newBlogs.forEach((blog, index) => {
      console.log(`${index + 1}. Title: "${blog.title}"`);
      console.log(`   Content length: ${blog.content.length} characters`);
      console.log(`   Created: ${blog.createdAt.toISOString()}`);
      console.log("");
    });

    return { insertedCount: result.insertedCount, blogs: newBlogs };
  } catch (error) {
    console.error("Error saving to MongoDB:", error.message);
    throw error;
  }
}

/**
 * Retrieves and logs statistics about the blogs collection.
 * @param {MongoClient} client - The MongoDB client instance.
 */
async function getCollectionStats(client) {
  try {
    const db = client.db(DATABASE_NAME);
    const collection = db.collection(COLLECTION_NAME);

    const totalBlogs = await collection.countDocuments();
    const recentBlogs = await collection
      .find({})
      .sort({ createdAt: -1 })
      .limit(3)
      .project({ title: 1, createdAt: 1 })
      .toArray();

    console.log(`\nüìä Database Statistics:`);
    console.log(`Total blogs in database: ${totalBlogs}`);

    if (recentBlogs.length > 0) {
      console.log("Most recent blogs:");
      recentBlogs.forEach((blog, index) => {
        console.log(
          `  ${index + 1}. "${blog.title}" (${blog.createdAt.toISOString()})`
        );
      });
    }
  } catch (error) {
    console.error("Error getting stats:", error.message);
  }
}

/**
 * Main function to orchestrate the blog import process.
 */
async function main() {
  let client;

  try {
    console.log("üöÄ Starting blog import process...");
    console.log(`üìÅ Reading from folder: ${TEXT_FILES_FOLDER}`);
    console.log(`üóÑÔ∏è  Database: ${DATABASE_NAME}`);
    console.log(`üìù Collection: ${COLLECTION_NAME}`);
    console.log("");

    // Connect to MongoDB
    client = await connectToMongoDB();

    // Read text files from folder
    const blogs = await readTextFiles(TEXT_FILES_FOLDER);

    if (blogs.length === 0) {
      console.log("‚ùå No blogs to process");
      return;
    }

    console.log(`\nüìö Found ${blogs.length} text file(s) to process`);

    // Save blogs to MongoDB
    const result = await saveBlogsToMongoDB(blogs, client);

    // Show database statistics
    await getCollectionStats(client);

    if (result.insertedCount > 0) {
      console.log("\nüéâ Import completed successfully!");
    } else {
      console.log("\n‚ú® Import completed (no new blogs added)");
    }
  } catch (error) {
    console.error("\n‚ùå Error in import process:", error.message);
    process.exit(1);
  } finally {
    // Close MongoDB connection
    if (client) {
      await client.close();
      console.log("\nüîå MongoDB connection closed");
    }
  }
}

// Run the script if called directly
if (require.main === module) {
  main().catch(console.error);
}

// Export functions for potential reuse
module.exports = {
  connectToMongoDB,
  readTextFiles,
  saveBlogsToMongoDB,
  main,
};
